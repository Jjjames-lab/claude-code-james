#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GLM-ASR API æµ‹è¯•è„šæœ¬
éªŒè¯APIåŠŸèƒ½ã€é™åˆ¶å’Œæœ€ä¼˜åˆ†æ®µç­–ç•¥
"""

import requests
import json
import time
from pathlib import Path

# APIé…ç½®
API_KEY = "dc7bdff46c004fcd87d050fef851f30d.lJaihNuvDsbIdL5y"
API_URL = "https://open.bigmodel.cn/api/paas/v4/audio/transcriptions"
MODEL = "glm-asr-2512"

def test_api_with_text():
    """
    æµ‹è¯•1: éªŒè¯APIåŸºç¡€åŠŸèƒ½
    æ³¨æ„ï¼šéœ€è¦æä¾›ä¸€ä¸ªçœŸå®çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    print("="*80)
    print("æµ‹è¯•1: éªŒè¯GLM-ASR APIåŸºç¡€åŠŸèƒ½")
    print("="*80)

    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    # ç”±äºæˆ‘æ— æ³•è®¿é—®çœŸå®éŸ³é¢‘ï¼Œè¿™é‡Œæä¾›æµ‹è¯•ä»£ç æ¡†æ¶
    audio_file_path = "test_audio.wav"  # éœ€è¦ç”¨æˆ·æä¾›

    print(f"\nğŸ“ APIé…ç½®:")
    print(f"  - API URL: {API_URL}")
    print(f"  - Model: {MODEL}")
    print(f"  - API Key: {API_KEY[:20]}...")

    print(f"\nâš ï¸  æ³¨æ„:")
    print(f"  - éœ€è¦æä¾›å®é™…çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆWAV/MP3æ ¼å¼ï¼‰")
    print(f"  - éŸ³é¢‘æ—¶é•¿é™åˆ¶ï¼šâ‰¤ 30ç§’")
    print(f"  - æ–‡ä»¶å¤§å°é™åˆ¶ï¼šâ‰¤ 25MB")
    print(f"  - æ”¯æŒæ ¼å¼ï¼šWAV, MP3, M4Aç­‰")

    return {
        "status": "ready",
        "note": "éœ€è¦å®é™…éŸ³é¢‘æ–‡ä»¶è¿›è¡Œæµ‹è¯•"
    }

def analyze_segmentation_strategy():
    """
    æµ‹è¯•2: åˆ†ææœ€ä¼˜åˆ†æ®µç­–ç•¥
    é’ˆå¯¹æ’­å®¢åœºæ™¯ï¼ˆé€šå¸¸30-120åˆ†é’Ÿï¼‰ï¼Œè®¾è®¡æœ€ä¼˜åˆ†æ®µæ–¹æ¡ˆ
    """
    print("\n" + "="*80)
    print("æµ‹è¯•2: åˆ†æéŸ³é¢‘åˆ†æ®µç­–ç•¥")
    print("="*80)

    # æ’­å®¢åœºæ™¯åˆ†æ
    podcast_durations = {
        "çŸ­æ’­å®¢": 30 * 60,  # 30åˆ†é’Ÿ
        "æ ‡å‡†æ’­å®¢": 60 * 60,  # 60åˆ†é’Ÿ
        "é•¿æ’­å®¢": 120 * 60,  # 120åˆ†é’Ÿ
    }

    print("\nğŸ“Š ä¸åŒé•¿åº¦æ’­å®¢çš„åˆ†æ®µæ–¹æ¡ˆ:")

    for name, duration in podcast_durations.items():
        segments = duration / 30  # 30ç§’ä¸€æ®µ
        print(f"\n{name} ({duration//60}åˆ†é’Ÿ):")
        print(f"  - æ€»æ—¶é•¿: {duration}ç§’")
        print(f"  - åˆ†æ®µæ•°: {int(segments)}æ®µ")
        print(f"  - APIè°ƒç”¨æ¬¡æ•°: {int(segments)}æ¬¡")

        # æˆæœ¬ä¼°ç®—ï¼ˆ16å…ƒ/ç™¾ä¸‡tokensï¼‰
        # å‡è®¾ï¼š1åˆ†é’Ÿ â‰ˆ 150-200 tokens
        minutes = duration / 60
        tokens_min = minutes * 150
        tokens_max = minutes * 200
        cost_min = (tokens_min / 1000000) * 16
        cost_max = (tokens_max / 1000000) * 16

        print(f"  - ä¼°ç®—tokens: {int(tokens_min/1000)}K-{int(tokens_max/1000)}K")
        print(f"  - ä¼°ç®—æˆæœ¬: Â¥{cost_min:.3f} - Â¥{cost_max:.3f}")

    print("\nâœ… æ¨èç­–ç•¥:")
    print("  1. ä½¿ç”¨25-28ç§’åˆ†æ®µï¼ˆç•™2-5ç§’ç¼“å†²ï¼‰")
    print("  2. é‡å 1-2ç§’ï¼ˆé¿å…å¥å­è¢«æˆªæ–­ï¼‰")
    print("  3. å¹¶å‘å¤„ç†ï¼ˆæå‡é€Ÿåº¦ï¼‰")

    return {
        "strategy": "overlap-25s-segments",
        "overlap": "2s",
        "concurrent": "3-5 segments"
    }

def design_optimal_solution():
    """
    æµ‹è¯•3: è®¾è®¡æœ€ä¼˜æŠ€æœ¯æ–¹æ¡ˆ
    """
    print("\n" + "="*80)
    print("æµ‹è¯•3: æœ€ä¼˜æŠ€æœ¯æ–¹æ¡ˆè®¾è®¡")
    print("="*80)

    print("\nğŸ¯ æ–¹æ¡ˆå¯¹æ¯”:")

    solutions = {
        "æ–¹æ¡ˆA - ç®€å•åˆ†æ®µ": {
            "description": "æŒ‰30ç§’ç¡¬åˆ‡åˆ†æ®µ",
            "pros": ["å®ç°ç®€å•", "è°ƒç”¨æ¬¡æ•°å°‘"],
            "cons": ["å¥å­å¯èƒ½è¢«æˆªæ–­", "æ‹¼æ¥ä¸è‡ªç„¶"],
            "score": 6
        },
        "æ–¹æ¡ˆB - é‡å åˆ†æ®µ": {
            "description": "25ç§’åˆ†æ®µ + 2ç§’é‡å ",
            "pros": ["é¿å…æˆªæ–­", "æ‹¼æ¥è‡ªç„¶", "å†—ä½™çº é”™"],
            "cons": ["è°ƒç”¨æ¬¡æ•°ç•¥å¤š", "æˆæœ¬ç•¥å¢"],
            "score": 9
        },
        "æ–¹æ¡ˆC - VADåˆ†æ®µ": {
            "description": "åŸºäºè¯­éŸ³æ´»åŠ¨æ£€æµ‹æ™ºèƒ½åˆ†æ®µ",
            "pros": ["æœ€è‡ªç„¶", "æŒ‰å¥å­åˆ†æ®µ"],
            "cons": ["å®ç°å¤æ‚", "éœ€è¦VADæ¨¡å‹"],
            "score": 7
        }
    }

    for name, solution in solutions.items():
        print(f"\n{name} (è¯„åˆ†: {solution['score']}/10)")
        print(f"  æè¿°: {solution['description']}")
        print(f"  ä¼˜ç‚¹: {', '.join(solution['pros'])}")
        print(f"  ç¼ºç‚¹: {', '.join(solution['cons'])}")

    print("\nâœ… æ¨èæ–¹æ¡ˆ: **æ–¹æ¡ˆB - é‡å åˆ†æ®µ**")
    print("\nç†ç”±:")
    print("  1. å¹³è¡¡äº†å®ç°å¤æ‚åº¦å’Œæ•ˆæœ")
    print("  2. é‡å ç­–ç•¥é¿å…äº†å¥å­æˆªæ–­")
    print("  3. æˆæœ¬å¢åŠ å¯æ§ï¼ˆçº¦8%ï¼‰")
    print("  4. é€‚åˆå¿«é€Ÿå¼€å‘MVP")

    return {
        "recommended": "æ–¹æ¡ˆB",
        "segment_length": 25,
        "overlap": 2,
        "implementation": "pydub + requests"
    }

def calculate_costs():
    """
    æµ‹è¯•4: ç²¾ç¡®æˆæœ¬æµ‹ç®—
    """
    print("\n" + "="*80)
    print("æµ‹è¯•4: æˆæœ¬ç²¾ç¡®æµ‹ç®—")
    print("="*80)

    # å‡è®¾å‚æ•°
    seconds_per_minute = 60
    avg_tokens_per_second = 2.5  # 150 tokens / 60ç§’
    price_per_million_tokens = 16

    scenarios = {
        "è½»åº¦ç”¨æˆ·": {"hours_per_month": 2, "users": 10},
        "æ ‡å‡†ç”¨æˆ·": {"hours_per_month": 5, "users": 100},
        "é‡åº¦ç”¨æˆ·": {"hours_per_month": 20, "users": 1000},
    }

    print("\nğŸ’° ä¸åŒç”¨æˆ·è§„æ¨¡æœˆåº¦æˆæœ¬:")

    for user_type, data in scenarios.items():
        total_hours = data["hours_per_month"] * data["users"]
        total_seconds = total_hours * 3600
        total_tokens = total_seconds * avg_tokens_per_second
        cost = (total_tokens / 1000000) * price_per_million_tokens

        print(f"\n{user_type}:")
        print(f"  - ç”¨æˆ·æ•°: {data['users']}")
        print(f"  - äººå‡è½¬å½•: {data['hours_per_month']}å°æ—¶/æœˆ")
        print(f"  - æ€»è½¬å½•æ—¶é•¿: {total_hours}å°æ—¶/æœˆ")
        print(f"  - ä¼°ç®—tokens: {int(total_tokens/1000)}K")
        print(f"  - æœˆåº¦æˆæœ¬: Â¥{cost:.2f}")

    # ç›ˆäºå¹³è¡¡åˆ†æ
    print("\nğŸ“Š ç›ˆäºå¹³è¡¡åˆ†æ:")
    print("  å‡è®¾å®šä»·: Â¥29/æœˆï¼ˆæ ‡å‡†ç‰ˆï¼‰")
    print("  å¯å˜æˆæœ¬: ~Â¥0.38/ç”¨æˆ·/æœˆ")
    print("  å›ºå®šæˆæœ¬: Â¥0ï¼ˆæ— æœåŠ¡å™¨ï¼‰")
    print("  ç›ˆäºå¹³è¡¡: ~2ä¸ªä»˜è´¹ç”¨æˆ·")

    return {
        "light_user_cost": 0.05,  # å…ƒ/æœˆ
        "standard_user_cost": 0.38,
        "heavy_user_cost": 3.04,
        "break_even_users": 2
    }

def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰§è¡Œæ‰€æœ‰æµ‹è¯•å’Œåˆ†æ
    """
    print("\n" + "ğŸš€"*40)
    print("GLM-ASR API éªŒè¯ä¸æ–¹æ¡ˆè®¾è®¡")
    print("ğŸš€"*40)

    start_time = time.time()

    # æ‰§è¡Œæµ‹è¯•
    result1 = test_api_with_text()
    result2 = analyze_segmentation_strategy()
    result3 = design_optimal_solution()
    result4 = calculate_costs()

    # æ±‡æ€»ç»“æœ
    elapsed_time = time.time() - start_time

    print("\n" + "="*80)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
    print("="*80)

    summary = {
        "api_status": "ready_for_testing",
        "recommended_strategy": "25ç§’åˆ†æ®µ + 2ç§’é‡å ",
        "estimated_cost_per_user": "Â¥0.29-0.38/æœˆ",
        "break_even_point": "2ä¸ªä»˜è´¹ç”¨æˆ·",
        "development_time": "~2-3å‘¨",
        "confidence": "high"
    }

    print(json.dumps(summary, indent=2, ensure_ascii=False))

    print("\n" + "="*80)
    print(f"âœ… åˆ†æå®Œæˆï¼è€—æ—¶: {elapsed_time:.2f}ç§’")
    print("="*80)

    print("\nğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
    print("  1. æä¾›çœŸå®éŸ³é¢‘æ–‡ä»¶è¿›è¡ŒAPIæµ‹è¯•")
    print("  2. å¼€å‘åç«¯åˆ†æ®µå¤„ç†æœåŠ¡")
    print("  3. å¼€å‘å‰ç«¯ç•Œé¢ï¼ˆä½¿ç”¨frontend-designæŠ€èƒ½ï¼‰")
    print("  4. æ•´åˆæµ‹è¯•")

    return summary

if __name__ == "__main__":
    main()
