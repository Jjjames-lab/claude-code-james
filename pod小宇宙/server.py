#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ’­å®¢é€å­—ç¨¿æœåŠ¡ - FastAPIæœåŠ¡å™¨
"""

import os

# æ·»åŠ  ~/.local/bin åˆ° PATHï¼ˆffmpeg å’Œ ffprobe çš„ä½ç½®ï¼‰
os.environ['PATH'] = os.path.expanduser('~/.local/bin') + ':' + os.environ.get('PATH', '')
import asyncio
import tempfile
import shutil
from pathlib import Path
from typing import List, Dict, Optional
import json

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import requests
from pydub import AudioSegment
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# ==================== é…ç½® ====================

API_KEY = "dc7bdff46c004fcd87d050fef851f30d.lJaihNuvDsbIdL5y"
API_URL = "https://open.bigmodel.cn/api/paas/v4/audio/transcriptions"
MODEL = "glm-asr-2512"
SEGMENT_LENGTH = 25  # åˆ†æ®µé•¿åº¦ï¼ˆç§’ï¼‰
OVERLAP = 2  # é‡å é•¿åº¦ï¼ˆç§’ï¼‰
MAX_WORKERS = 3  # å¹¶å‘å¤„ç†æ•°

# ffmpeg è·¯å¾„é…ç½®
FFMPEG_PATH = os.path.expanduser("~/.local/bin/ffmpeg")
FFPROBE_PATH = os.path.expanduser("~/.local/bin/ffprobe")

# è®¾ç½® pydub ä½¿ç”¨æŒ‡å®šçš„ ffmpeg å’Œ ffprobe
if os.path.exists(FFMPEG_PATH):
    AudioSegment.converter = FFMPEG_PATH
    AudioSegment.ffprobe = FFPROBE_PATH
    print(f"âœ… ä½¿ç”¨ ffmpeg: {FFMPEG_PATH}")
    print(f"âœ… ä½¿ç”¨ ffprobe: {FFPROBE_PATH}")
else:
    print(f"âš ï¸  è­¦å‘Š: ffmpeg æœªæ‰¾åˆ°")
    print(f"   è·¯å¾„: {FFMPEG_PATH}")

# ==================== FastAPI App ====================

app = FastAPI(
    title="æ’­å®¢é€å­—ç¨¿æœåŠ¡ API",
    description="AIé©±åŠ¨çš„æ’­å®¢é€å­—ç¨¿ç”Ÿæˆå·¥å…·",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== æ ¸å¿ƒåŠŸèƒ½ ====================

class GLMASRTranscriber:
    """GLM-ASRè½¬å†™å™¨"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.api_url = API_URL
        self.session = requests.Session()

    def transcribe_segment(self, audio_path: str) -> Dict:
        """
        è½¬å†™å•ä¸ªéŸ³é¢‘ç‰‡æ®µï¼ˆâ‰¤30ç§’ï¼‰

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            APIå“åº”ç»“æœ
        """
        if not Path(audio_path).exists():
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")

        headers = {
            'Authorization': f'Bearer {self.api_key}'
        }

        with open(audio_path, 'rb') as audio_file:
            files = {'file': audio_file}
            data = {
                'model': MODEL,
                'stream': 'false'
            }

            try:
                response = requests.post(
                    self.api_url,
                    headers=headers,
                    files=files,
                    data=data,
                    timeout=60
                )
                response.raise_for_status()
                return response.json()
            except requests.exceptions.RequestException as e:
                print(f"APIè°ƒç”¨å¤±è´¥: {e}")
                print(f"å“åº”å†…å®¹: {response.text if hasattr(response, 'text') else 'N/A'}")
                raise

def segment_audio(audio_path: str, segment_length: int = SEGMENT_LENGTH, overlap: int = OVERLAP) -> List[Dict]:
    """
    åˆ†å‰²éŸ³é¢‘æ–‡ä»¶

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        segment_length: åˆ†æ®µé•¿åº¦ï¼ˆç§’ï¼‰
        overlap: é‡å é•¿åº¦ï¼ˆç§’ï¼‰

    Returns:
        åˆ†æ®µä¿¡æ¯åˆ—è¡¨
    """
    audio = AudioSegment.from_file(audio_path)
    duration_ms = len(audio)
    segment_length_ms = segment_length * 1000
    overlap_ms = overlap * 1000

    segments = []
    start_ms = 0
    segment_index = 0

    while start_ms < duration_ms:
        end_ms = min(start_ms + segment_length_ms + overlap_ms, duration_ms)
        actual_duration_ms = end_ms - start_ms

        segments.append({
            'index': segment_index,
            'start_ms': start_ms,
            'end_ms': end_ms,
            'duration_sec': actual_duration_ms / 1000
        })

        start_ms += segment_length_ms
        segment_index += 1

    return segments

def extract_audio_segment(audio_path: str, start_ms: int, end_ms: int, output_path: str) -> str:
    """
    æå–éŸ³é¢‘ç‰‡æ®µå¹¶ä¿å­˜åˆ°æ–‡ä»¶

    Args:
        audio_path: åŸéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        start_ms: å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        end_ms: ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

    Returns:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    audio = AudioSegment.from_file(audio_path)
    segment = audio[start_ms:end_ms]
    segment.export(output_path, format="mp3")
    return output_path

def process_audio_upload(
    file_path: str,
    filename: str,
    transcriber: GLMASRTranscriber
) -> Dict:
    """
    å¤„ç†éŸ³é¢‘ä¸Šä¼ å¹¶è½¬å†™

    Args:
        file_path: ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
        filename: åŸå§‹æ–‡ä»¶å
        transcriber: è½¬å†™å™¨å®ä¾‹

    Returns:
        è½¬å†™ç»“æœ
    """
    start_time = time.time()

    print(f"\n{'='*60}")
    print(f"ğŸ™ï¸  å¼€å§‹è½¬å†™: {filename}")
    print(f"{'='*60}")

    # 1. åˆ†æ®µå¤„ç†
    print(f"ğŸ“Š æ­¥éª¤1: éŸ³é¢‘åˆ†æ®µ...")
    segments_info = segment_audio(file_path)
    print(f"   âœ… åˆ†æ®µå®Œæˆ: {len(segments_info)}æ®µ")

    # 2. åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜ç‰‡æ®µ
    temp_dir = tempfile.mkdtemp(prefix="podcast_segments_")

    try:
        # 3. æå–éŸ³é¢‘ç‰‡æ®µ
        print(f"\nğŸµ æ­¥éª¤2: æå–éŸ³é¢‘ç‰‡æ®µ...")
        segment_files = []
        for seg in segments_info:
            output_path = os.path.join(temp_dir, f"segment_{seg['index']:03d}.mp3")
            extract_audio_segment(file_path, seg['start_ms'], seg['end_ms'], output_path)
            segment_files.append({
                'info': seg,
                'path': output_path
            })
        print(f"   âœ… æå–å®Œæˆ: {len(segment_files)}ä¸ªç‰‡æ®µ")

        # 4. å¹¶å‘è½¬å†™
        print(f"\nğŸ”„ æ­¥éª¤3: å¹¶å‘è½¬å†™ (å¹¶å‘æ•°={MAX_WORKERS})...")
        transcribed_segments = []
        total_tokens = 0

        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_segment = {
                executor.submit(transcriber.transcribe_segment, seg['path']): seg
                for seg in segment_files
            }

            for i, future in enumerate(as_completed(future_to_segment), 1):
                seg = future_to_segment[future]
                try:
                    result = future.result()

                    # è§£æç»“æœ
                    if 'text' in result:
                        text = result['text']
                    else:
                        text = ""

                    # è®¡ç®—tokenæ•°ï¼ˆç²—ç•¥ä¼°ç®—ï¼š1å­—ç¬¦â‰ˆ1tokenï¼‰
                    tokens = len(text)
                    total_tokens += tokens

                    transcribed_segments.append({
                        'text': text,
                        'start': seg['info']['start_ms'] / 1000,
                        'end': seg['info']['end_ms'] / 1000,
                        'speaker': 'SPEAKER_00' if seg['info']['index'] % 2 == 0 else 'SPEAKER_01'
                    })

                    print(f"   è¿›åº¦: {i}/{len(segment_files)} - {text[:50]}...")

                except Exception as e:
                    print(f"   âš ï¸  ç‰‡æ®µ{seg['info']['index']}è½¬å†™å¤±è´¥: {e}")
                    # æ·»åŠ ç©ºç»“æœä»¥ä¿æŒé¡ºåº
                    transcribed_segments.append({
                        'text': "",
                        'start': seg['info']['start_ms'] / 1000,
                        'end': seg['info']['end_ms'] / 1000,
                        'speaker': 'SPEAKER_00'
                    })

        # æŒ‰ç´¢å¼•æ’åº
        transcribed_segments.sort(key=lambda x: x['start'])

        # 5. åˆå¹¶ç»“æœ
        print(f"\nâœ¨ æ­¥éª¤4: åˆå¹¶ç»“æœ...")
        full_text = ' '.join([seg['text'] for seg in transcribed_segments if seg['text']])
        word_count = len(full_text)
        duration = max([seg['end'] for seg in transcribed_segments]) if transcribed_segments else 0
        processing_time = time.time() - start_time

        # è®¡ç®—æˆæœ¬ï¼ˆ16å…ƒ/ç™¾ä¸‡tokensï¼‰
        total_cost = (total_tokens / 1000000) * 16

        print(f"\nâœ… è½¬å†™å®Œæˆ!")
        print(f"   - æ—¶é•¿: {duration:.1f}ç§’")
        print(f"   - å­—æ•°: {word_count}")
        print(f"   - tokens: {total_tokens}")
        print(f"   - è€—æ—¶: {processing_time:.1f}ç§’")
        print(f"   - æˆæœ¬: Â¥{total_cost:.4f}")

        return {
            'fullText': full_text,
            'segments': transcribed_segments,
            'duration': duration,
            'wordCount': word_count
        }

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        shutil.rmtree(temp_dir, ignore_errors=True)

# ==================== APIè·¯ç”± ====================

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "æ’­å®¢é€å­—ç¨¿æœåŠ¡ API",
        "version": "1.0.0",
        "status": "running"
    }

@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy"}

@app.post("/transcribe")
async def transcribe(file: UploadFile = File(...)):
    """
    è½¬å†™éŸ³é¢‘æ–‡ä»¶

    Args:
        file: ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶

    Returns:
        è½¬å†™ç»“æœ
    """
    # éªŒè¯æ–‡ä»¶ç±»å‹
    allowed_types = ['audio/mpeg', 'audio/mp3', 'audio/wav', 'audio/m4a', 'audio/x-m4a', 'audio/mp4']
    if file.content_type not in allowed_types:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file.content_type}ã€‚è¯·ä¸Šä¼  MP3ã€WAV æˆ– M4A æ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶ã€‚"
        )

    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix)
    temp_path = temp_file.name

    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        with open(temp_path, 'wb') as f:
            shutil.copyfileobj(file.file, f)

        # åˆ›å»ºè½¬å†™å™¨
        transcriber = GLMASRTranscriber(api_key=API_KEY)

        # å¤„ç†éŸ³é¢‘
        result = process_audio_upload(temp_path, file.filename, transcriber)

        return JSONResponse(content=result)

    except Exception as e:
        print(f"é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=f"è½¬å†™å¤±è´¥: {str(e)}")

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_path):
            os.unlink(temp_path)

# ==================== ä¸»ç¨‹åº ====================

if __name__ == "__main__":
    print("ğŸ™ï¸  æ’­å®¢é€å­—ç¨¿æœåŠ¡")
    print("="*60)
    print("âœ… FastAPIæœåŠ¡å™¨å¯åŠ¨ä¸­...")
    print(f"ğŸ“ APIåœ°å€: http://localhost:8000")
    print(f"ğŸ“ æ–‡æ¡£åœ°å€: http://localhost:8000/docs")
    print(f"ğŸ“ å¥åº·æ£€æŸ¥: http://localhost:8000/health")
    print("="*60)

    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
