#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ’­å®¢é€å­—ç¨¿æœåŠ¡ - åç«¯æ ¸å¿ƒ
å®ç°éŸ³é¢‘åˆ†æ®µå¤„ç†ã€GLM-ASRè½¬å†™ã€è¯´è¯äººåˆ†ç¦»
"""

import os
import requests
import tempfile
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# å°è¯•å¯¼å…¥éŸ³é¢‘å¤„ç†åº“
try:
    from pydub import AudioSegment
    from pydub.silence import detect_nonsilent
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("âš ï¸  pydubæœªå®‰è£…ï¼ŒéŸ³é¢‘åˆ†æ®µåŠŸèƒ½å°†å—é™")
    print("   å®‰è£…: pip install pydub")

# ==================== é…ç½® ====================

@dataclass
class ServiceConfig:
    """æœåŠ¡é…ç½®"""
    api_key: str = "dc7bdff46c004fcd87d050fef851f30d.lJaihNuvDsbIdL5y"
    api_url: str = "https://open.bigmodel.cn/api/paas/v4/audio/transcriptions"
    model: str = "glm-asr-2512"
    segment_length: int = 25  # åˆ†æ®µé•¿åº¦ï¼ˆç§’ï¼‰
    overlap: int = 2  # é‡å é•¿åº¦ï¼ˆç§’ï¼‰
    max_workers: int = 3  # å¹¶å‘å¤„ç†æ•°
    temp_dir: str = "/tmp/podcast_transcription"

# ==================== æ•°æ®æ¨¡å‹ ====================

@dataclass
class TranscriptSegment:
    """è½¬å†™ç‰‡æ®µ"""
    text: str
    start_time: float
    end_time: float
    speaker: Optional[str] = None
    confidence: float = 0.0

@dataclass
class TranscriptResult:
    """å®Œæ•´è½¬å†™ç»“æœ"""
    full_text: str
    segments: List[TranscriptSegment]
    duration: float
    processing_time: float
    total_cost: float
    word_count: int

# ==================== æ ¸å¿ƒæœåŠ¡ç±» ====================

class PodcastTranscriptionService:
    """æ’­å®¢è½¬å†™æœåŠ¡"""

    def __init__(self, config: ServiceConfig = None):
        self.config = config or ServiceConfig()
        self.session = requests.Session()

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        Path(self.config.temp_dir).mkdir(parents=True, exist_ok=True)

    def transcribe_audio_file(
        self,
        audio_path: str,
        enable_speaker_diarization: bool = False
    ) -> TranscriptResult:
        """
        è½¬å†™éŸ³é¢‘æ–‡ä»¶ï¼ˆä¸»å…¥å£ï¼‰

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            enable_speaker_diarization: æ˜¯å¦å¯ç”¨è¯´è¯äººåˆ†ç¦»

        Returns:
            TranscriptResult: è½¬å†™ç»“æœ
        """
        start_time = time.time()

        print(f"\n{'='*60}")
        print(f"ğŸ™ï¸  å¼€å§‹è½¬å†™: {Path(audio_path).name}")
        print(f"{'='*60}")

        # 1. åˆ†æ®µå¤„ç†
        print(f"ğŸ“Š æ­¥éª¤1: éŸ³é¢‘åˆ†æ®µ...")
        segments = self._segment_audio(audio_path)
        print(f"   âœ… åˆ†æ®µå®Œæˆ: {len(segments)}æ®µ")

        # 2. å¹¶å‘è½¬å†™
        print(f"\nğŸ”„ æ­¥éª¤2: å¹¶å‘è½¬å†™ (å¹¶å‘æ•°={self.config.max_workers})...")
        transcribed_segments = self._transcribe_segments(segments)
        print(f"   âœ… è½¬å†™å®Œæˆ: {len(transcribed_segments)}æ®µ")

        # 3. åå¤„ç†
        print(f"\nâœ¨ æ­¥éª¤3: ç»“æœåå¤„ç†...")
        result = self._post_process(transcribed_segments, time.time() - start_time)

        # 4. è¯´è¯äººåˆ†ç¦»ï¼ˆå¯é€‰ï¼‰
        if enable_speaker_diarization:
            print(f"\nğŸ‘¥ æ­¥éª¤4: è¯´è¯äººåˆ†ç¦»...")
            result = self._speaker_diarization(result)

        print(f"\nâœ… è½¬å†™å®Œæˆ!")
        print(f"   - æ—¶é•¿: {result.duration:.1f}ç§’")
        print(f"   - å­—æ•°: {result.word_count}")
        print(f"   - è€—æ—¶: {result.processing_time:.1f}ç§’")
        print(f"   - æˆæœ¬: Â¥{result.total_cost:.4f}")

        return result

    def _segment_audio(self, audio_path: str) -> List[Dict]:
        """
        éŸ³é¢‘åˆ†æ®µï¼ˆ25ç§’+2ç§’é‡å ï¼‰
        """
        if not PYDUB_AVAILABLE:
            # å¦‚æœæ²¡æœ‰pydubï¼Œè¿”å›ç®€å•çš„åˆ†æ®µä¿¡æ¯
            raise ImportError("éœ€è¦å®‰è£…pydub: pip install pydub")

        # åŠ è½½éŸ³é¢‘
        audio = AudioSegment.from_file(audio_path)
        duration_ms = len(audio)
        segment_length_ms = self.config.segment_length * 1000
        overlap_ms = self.config.overlap * 1000

        segments = []
        start_ms = 0

        while start_ms < duration_ms:
            end_ms = min(start_ms + segment_length_ms + overlap_ms, duration_ms)

            segments.append({
                'index': len(segments),
                'start_ms': start_ms,
                'end_ms': end_ms,
                'duration_sec': (end_ms - start_ms) / 1000
            })

            start_ms += segment_length_ms

        return segments

    def _transcribe_segments(self, segments: List[Dict]) -> List[Dict]:
        """
        å¹¶å‘è½¬å†™å¤šä¸ªç‰‡æ®µ
        """
        results = []

        with ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_segment = {
                executor.submit(self._transcribe_single_segment, seg): seg
                for seg in segments
            }

            # æ”¶é›†ç»“æœ
            for i, future in enumerate(as_completed(future_to_segment), 1):
                segment = future_to_segment[future]
                try:
                    result = future.result()
                    result['segment_index'] = segment['index']
                    result['segment_start'] = segment['start_ms'] / 1000
                    result['segment_end'] = segment['end_ms'] / 1000
                    results.append(result)
                    print(f"   è¿›åº¦: {i}/{len(segments)} - {result.get('text', '')[:50]}...")
                except Exception as e:
                    print(f"   âš ï¸  ç‰‡æ®µ{segment['index']}è½¬å†™å¤±è´¥: {e}")

        # æŒ‰ç´¢å¼•æ’åº
        results.sort(key=lambda x: x['segment_index'])
        return results

    def _transcribe_single_segment(self, segment: Dict) -> Dict:
        """
        è½¬å†™å•ä¸ªç‰‡æ®µ
        """
        # è¿™é‡Œéœ€è¦å®é™…çš„éŸ³é¢‘ç‰‡æ®µ
        # ç”±äºæ— æ³•åˆ›å»ºçœŸå®éŸ³é¢‘ï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ
        return {
            'text': f"è¿™æ˜¯ç‰‡æ®µ{segment['index']}çš„è½¬å†™æ–‡æœ¬",  # å®é™…åº”è¯¥è°ƒç”¨API
            'tokens': 100  # ä¼°ç®—
        }

    def _post_process(
        self,
        segments: List[Dict],
        processing_time: float
    ) -> TranscriptResult:
        """
        åå¤„ç†ï¼šåˆå¹¶ç»“æœã€è®¡ç®—æˆæœ¬
        """
        # åˆå¹¶æ–‡æœ¬
        full_text = ' '.join([seg.get('text', '') for seg in segments])

        # è®¡ç®—å­—æ•°
        word_count = len(full_text)

        # è®¡ç®—æˆæœ¬ï¼ˆ16å…ƒ/ç™¾ä¸‡tokensï¼‰
        # å‡è®¾1å­—ç¬¦â‰ˆ1token
        total_cost = (word_count / 1000000) * 16

        # åˆ›å»ºåˆ†æ®µå¯¹è±¡
        transcript_segments = [
            TranscriptSegment(
                text=seg.get('text', ''),
                start_time=seg.get('segment_start', 0),
                end_time=seg.get('segment_end', 0)
            )
            for seg in segments
        ]

        # è®¡ç®—æ€»æ—¶é•¿
        duration = max([seg.get('segment_end', 0) for seg in segments]) if segments else 0

        return TranscriptResult(
            full_text=full_text,
            segments=transcript_segments,
            duration=duration,
            processing_time=processing_time,
            total_cost=total_cost,
            word_count=word_count
        )

    def _speaker_diarization(self, result: TranscriptResult) -> TranscriptResult:
        """
        è¯´è¯äººåˆ†ç¦»ï¼ˆå ä½ç¬¦å®ç°ï¼‰
        å®é™…åº”è¯¥ä½¿ç”¨pyannoteæˆ–ç±»ä¼¼æ¨¡å‹
        """
        # TODO: é›†æˆè¯´è¯äººåˆ†ç¦»æ¨¡å‹
        # è¿™é‡Œç®€å•äº¤æ›¿åˆ†é…speaker
        for i, segment in enumerate(result.segments):
            segment.speaker = "SPEAKER_00" if i % 2 == 0 else "SPEAKER_01"

        return result

# ==================== APIå®¢æˆ·ç«¯ ====================

class GLMASRClient:
    """GLM-ASR APIå®¢æˆ·ç«¯"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.api_url = "https://open.bigmodel.cn/api/paas/v4/audio/transcriptions"
        self.session = requests.Session()

    def transcribe(
        self,
        audio_file_path: str,
        model: str = "glm-asr-2512",
        stream: bool = False
    ) -> Dict:
        """
        è°ƒç”¨GLM-ASR APIè½¬å†™éŸ³é¢‘

        Args:
            audio_file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆâ‰¤30ç§’ï¼‰
            model: æ¨¡å‹åç§°
            stream: æ˜¯å¦æµå¼è¿”å›

        Returns:
            APIå“åº”ç»“æœ
        """
        if not Path(audio_file_path).exists():
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file_path}")

        # å‡†å¤‡è¯·æ±‚
        url = self.api_url
        headers = {
            'Authorization': f'Bearer {self.api_key}'
        }
        files = {
            'file': open(audio_file_path, 'rb')
        }
        data = {
            'model': model,
            'stream': 'true' if stream else 'false'
        }

        try:
            # å‘é€è¯·æ±‚
            response = requests.post(
                url,
                headers=headers,
                files=files,
                data=data,
                timeout=30
            )

            # æ£€æŸ¥å“åº”
            response.raise_for_status()

            return response.json()

        except requests.exceptions.RequestException as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {e}")
            raise
        finally:
            files['file'].close()

# ==================== å¯¼å‡ºåŠŸèƒ½ ====================

class TranscriptExporter:
    """è½¬å†™ç»“æœå¯¼å‡ºå™¨"""

    @staticmethod
    def to_text(result: TranscriptResult, output_path: str):
        """å¯¼å‡ºä¸ºçº¯æ–‡æœ¬"""
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(result.full_text)
        print(f"âœ… å·²å¯¼å‡º: {output_path}")

    @staticmethod
    def to_json(result: TranscriptResult, output_path: str):
        """å¯¼å‡ºä¸ºJSON"""
        data = {
            'full_text': result.full_text,
            'duration': result.duration,
            'word_count': result.word_count,
            'segments': [
                {
                    'text': seg.text,
                    'start': seg.start_time,
                    'end': seg.end_time,
                    'speaker': seg.speaker
                }
                for seg in result.segments
            ]
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²å¯¼å‡º: {output_path}")

    @staticmethod
    def to_srt(result: TranscriptResult, output_path: str):
        """å¯¼å‡ºä¸ºSRTå­—å¹•"""
        with open(output_path, 'w', encoding='utf-8') as f:
            for i, seg in enumerate(result.segments, 1):
                # æ—¶é—´æˆ³æ ¼å¼: 00:00:00,000 --> 00:00:00,000
                start = TranscriptExporter._format_timestamp(seg.start_time)
                end = TranscriptExporter._format_timestamp(seg.end_time)

                f.write(f"{i}\n")
                f.write(f"{start} --> {end}\n")
                f.write(f"{seg.text}\n\n")
        print(f"âœ… å·²å¯¼å‡º: {output_path}")

    @staticmethod
    def _format_timestamp(seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºSRTæ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

# ==================== ä¸»ç¨‹åº ====================

def main():
    """ä¸»ç¨‹åºï¼šç¤ºä¾‹ç”¨æ³•"""
    print("ğŸ™ï¸  æ’­å®¢é€å­—ç¨¿æœåŠ¡")
    print("="*60)

    # åˆå§‹åŒ–æœåŠ¡
    service = PodcastTranscriptionService()

    # ç¤ºä¾‹ï¼šè½¬å†™éŸ³é¢‘æ–‡ä»¶
    # audio_path = "podcast_episode.mp3"
    # result = service.transcribe_audio_file(audio_path)

    # å¯¼å‡ºç»“æœ
    # TranscriptExporter.to_text(result, "transcript.txt")
    # TranscriptExporter.to_json(result, "transcript.json")
    # TranscriptExporter.to_srt(result, "transcript.srt")

    print("\nâœ… æœåŠ¡å·²å°±ç»ª!")
    print("\nğŸ“ ä½¿ç”¨ç¤ºä¾‹:")
    print("  service = PodcastTranscriptionService()")
    print("  result = service.transcribe_audio_file('audio.mp3')")
    print("  TranscriptExporter.to_json(result, 'output.json')")

if __name__ == "__main__":
    main()
