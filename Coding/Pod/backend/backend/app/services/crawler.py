"""
å°å®‡å®™çˆ¬è™«æœåŠ¡
ä½¿ç”¨ Playwright å¤„ç†åçˆ¬è™«ï¼Œæå–éŸ³é¢‘å’Œå…ƒæ•°æ®
"""
import asyncio
import re
from typing import Dict, Optional
from playwright.async_api import async_playwright, Browser, Page
from app.utils.logger import logger
from app.utils.errors import Error403Exception, Error404Exception, Error504Exception, InvalidURLException


class XiaoyuzhouCrawler:
    """å°å®‡å®™çˆ¬è™«"""

    def __init__(self):
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None

    async def init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        if self.browser is None:
            playwright = await async_playwright().start()
            # ä½¿ç”¨ Chromium æµè§ˆå™¨
            self.browser = await playwright.chromium.launch(
                headless=True,  # æ— å¤´æ¨¡å¼
                args=['--disable-blink-features=AutomationControlled']  # åçˆ¬è™«å¯¹ç­–
            )
            logger.info("Playwright æµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸ")

    async def close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.browser:
            await self.browser.close()
            self.browser = None
            logger.info("Playwright æµè§ˆå™¨å·²å…³é—­")

    def _validate_url(self, url: str) -> bool:
        """éªŒè¯ URL æ ¼å¼ï¼ˆæ”¯æŒ episode å’Œ podcast ä¸¤ç§é“¾æ¥ï¼‰"""
        # æ”¯æŒå•é›†é“¾æ¥: /episode/[id]
        # æ”¯æŒæ’­å®¢ä¸»é¡µ: /podcast/[id]
        episode_pattern = r'https?://(www\.)?xiaoyuzhoufm\.com/episode/[a-zA-Z0-9]+'
        podcast_pattern = r'https?://(www\.)?xiaoyuzhoufm\.com/podcast/[a-zA-Z0-9]+'

        if not (re.match(episode_pattern, url) or re.match(podcast_pattern, url)):
            return False
        return True

    def _extract_episode_id(self, url: str) -> str:
        """ä» URL ä¸­æå–èŠ‚ç›® ID"""
        match = re.search(r'/episode/([a-zA-Z0-9]+)', url)
        if match:
            return match.group(1)
        raise InvalidURLException(f"æ— æ³•ä» URL ä¸­æå–èŠ‚ç›® ID: {url}")

    def _extract_podcast_id(self, url: str) -> str:
        """ä» URL ä¸­æå–æ’­å®¢ ID"""
        match = re.search(r'/podcast/([a-zA-Z0-9]+)', url)
        if match:
            return match.group(1)
        raise InvalidURLException(f"æ— æ³•ä» URL ä¸­æå–æ’­å®¢ ID: {url}")

    def _is_podcast_url(self, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ’­å®¢ä¸»é¡µé“¾æ¥"""
        return bool(re.search(r'/podcast/[a-zA-Z0-9]+', url))

    def _is_playback_page(self, url: str) -> bool:
        """åˆ¤æ–­URLæ˜¯å¦ä¸ºæ’­æ”¾é¡µé¢è€ŒééŸ³é¢‘æ–‡ä»¶

        Returns:
            True: æ’­æ”¾é¡µé¢ï¼ˆéœ€è¦è¿›ä¸€æ­¥æå–ï¼‰
            False: éŸ³é¢‘æ–‡ä»¶ç›´æ¥é“¾æ¥
        """
        # æ£€æŸ¥æ˜¯å¦åŒ…å«éŸ³é¢‘æ–‡ä»¶æ‰©å±•å
        audio_extensions = ('.mp3', '.m4a', '.mp4', '.wav', '.ogg', '.opus', '.aac')
        if url.lower().endswith(audio_extensions):
            return False  # æ˜¯éŸ³é¢‘æ–‡ä»¶

        # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„æ’­æ”¾é¡µé¢åŸŸå
        playback_domains = ['ximalaya.com', 'jt.ximalaya.com', 'qingting.fm', 'lizhi.fm']
        if any(domain in url for domain in playback_domains):
            # å¦‚æœURLè·¯å¾„ä¸åŒ…å«éŸ³é¢‘æ‰©å±•åï¼Œå¾ˆå¯èƒ½æ˜¯æ’­æ”¾é¡µé¢
            return True

        # æ£€æŸ¥URLè·¯å¾„æ¨¡å¼
        if any(pattern in url for pattern in ['/episode/', '/audio/', '/play/', '/player/']):
            return True

        return False

    async def parse_episode(self, url: str) -> Dict:
        """
        è§£æå°å®‡å®™èŠ‚ç›®é“¾æ¥

        Args:
            url: å°å®‡å®™èŠ‚ç›®é“¾æ¥

        Returns:
            åŒ…å«éŸ³é¢‘å’Œå…ƒæ•°æ®çš„å­—å…¸

        Raises:
            InvalidURLException: URL æ ¼å¼æ— æ•ˆ
            Error403Exception: åçˆ¬è™«æ‹¦æˆª
            Error404Exception: èŠ‚ç›®ä¸å­˜åœ¨
            Error504Exception: è¯·æ±‚è¶…æ—¶
        """
        try:
            # 1. éªŒè¯ URL
            if not self._validate_url(url):
                raise InvalidURLException(f"æ— æ•ˆçš„å°å®‡å®™é“¾æ¥æ ¼å¼: {url}")

            episode_id = self._extract_episode_id(url)
            logger.info(f"å¼€å§‹è§£æèŠ‚ç›® {episode_id}")

            # 2. åˆå§‹åŒ–æµè§ˆå™¨
            await self.init_browser()

            # 3. åˆ›å»ºé¡µé¢
            if self.page is None:
                self.page = await self.browser.new_page(
                    user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                )

            # 4. è®¾ç½®è¶…æ—¶ï¼ˆå¢åŠ åˆ°60ç§’ï¼‰
            timeout_ms = 60000  # 60 ç§’

            # 5. è®¿é—®é¡µé¢ï¼ˆä½¿ç”¨ domcontentloaded è€Œä¸æ˜¯ networkidleï¼Œæ›´å¿«ï¼‰
            try:
                await self.page.goto(url, timeout=timeout_ms, wait_until="domcontentloaded")
                logger.debug(f"é¡µé¢åŠ è½½æˆåŠŸ: {url}")
            except asyncio.TimeoutError:
                logger.error(f"è®¿é—®é¡µé¢è¶…æ—¶: {url}")
                raise Error504Exception(f"è®¿é—®é¡µé¢è¶…æ—¶: {url}")

            # 6. æ£€æŸ¥æ˜¯å¦è¢«åçˆ¬è™«æ‹¦æˆª
            page_content = await self.page.content()
            if "è®¿é—®è¿‡äºé¢‘ç¹" in page_content or "è¯·å…ˆç™»å½•" in page_content:
                logger.warning(f"è¢«åçˆ¬è™«æ‹¦æˆª: {url}")
                raise Error403Exception("è¢«åçˆ¬è™«æœºåˆ¶æ‹¦æˆªï¼Œè¯·ç¨åé‡è¯•")

            # 7. æ£€æŸ¥é¡µé¢æ˜¯å¦å­˜åœ¨ï¼ˆ404ï¼‰
            if "é¡µé¢ä¸å­˜åœ¨" in page_content or "404" in await self.page.title():
                logger.warning(f"èŠ‚ç›®ä¸å­˜åœ¨: {url}")
                raise Error404Exception(f"èŠ‚ç›®é“¾æ¥å·²å¤±æ•ˆæˆ–ä¸å­˜åœ¨: {url}")

            # 8. æå–æ•°æ®
            # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½ï¼ˆä¸ç­‰å¾…ç‰¹å®šå…ƒç´ ï¼‰
            await self.page.wait_for_load_state("networkidle", timeout=timeout_ms)

            # å°è¯•ä»é¡µé¢ JSON æ•°æ®ä¸­æå–
            data = await self._extract_data_from_page()

            logger.info(f"èŠ‚ç›®è§£ææˆåŠŸ: {episode_id}")
            return data

        except (InvalidURLException, Error403Exception, Error404Exception, Error504Exception):
            raise
        except Exception as e:
            logger.error(f"è§£æèŠ‚ç›®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
            raise Error504Exception(f"è§£æå¤±è´¥: {str(e)}")

    async def parse_podcast_homepage(self, url: str, limit: int = 5, offset: int = 0) -> Dict:
        """
        è§£æå°å®‡å®™æ’­å®¢ä¸»é¡µé“¾æ¥

        Args:
            url: å°å®‡å®™æ’­å®¢ä¸»é¡µé“¾æ¥

        Returns:
            åŒ…å«æ’­å®¢ä¿¡æ¯å’Œæœ€æ–°èŠ‚ç›®åˆ—è¡¨çš„å­—å…¸

        Raises:
            InvalidURLException: URL æ ¼å¼æ— æ•ˆ
            Error403Exception: åçˆ¬è™«æ‹¦æˆª
            Error404Exception: æ’­å®¢ä¸å­˜åœ¨
            Error504Exception: è¯·æ±‚è¶…æ—¶
        """
        try:
            # 1. éªŒè¯ URL
            if not self._validate_url(url):
                raise InvalidURLException(f"æ— æ•ˆçš„å°å®‡å®™é“¾æ¥æ ¼å¼: {url}")

            if not self._is_podcast_url(url):
                raise InvalidURLException(f"è¯¥é“¾æ¥ä¸æ˜¯æ’­å®¢ä¸»é¡µé“¾æ¥: {url}")

            podcast_id = self._extract_podcast_id(url)
            logger.info(f"å¼€å§‹è§£ææ’­å®¢ä¸»é¡µ {podcast_id}")

            # 2. åˆå§‹åŒ–æµè§ˆå™¨
            await self.init_browser()

            # 3. åˆ›å»ºé¡µé¢
            if self.page is None:
                self.page = await self.browser.new_page(
                    user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                )

            # 4. è®¾ç½®è¶…æ—¶
            timeout_ms = 60000

            # 5. è®¿é—®é¡µé¢
            try:
                await self.page.goto(url, timeout=timeout_ms, wait_until="domcontentloaded")
                logger.debug(f"æ’­å®¢ä¸»é¡µåŠ è½½æˆåŠŸ: {url}")
            except asyncio.TimeoutError:
                logger.error(f"è®¿é—®æ’­å®¢ä¸»é¡µè¶…æ—¶: {url}")
                raise Error504Exception(f"è®¿é—®æ’­å®¢ä¸»é¡µè¶…æ—¶: {url}")

            # 6. æ£€æŸ¥åçˆ¬è™«
            page_content = await self.page.content()
            if "è®¿é—®è¿‡äºé¢‘ç¹" in page_content or "è¯·å…ˆç™»å½•" in page_content:
                logger.warning(f"è¢«åçˆ¬è™«æ‹¦æˆª: {url}")
                raise Error403Exception("è¢«åçˆ¬è™«æœºåˆ¶æ‹¦æˆªï¼Œè¯·ç¨åé‡è¯•")

            # 7. æ£€æŸ¥é¡µé¢æ˜¯å¦å­˜åœ¨
            if "é¡µé¢ä¸å­˜åœ¨" in page_content or "404" in await self.page.title():
                logger.warning(f"æ’­å®¢ä¸å­˜åœ¨: {url}")
                raise Error404Exception(f"æ’­å®¢é“¾æ¥å·²å¤±æ•ˆæˆ–ä¸å­˜åœ¨: {url}")

            # 8. ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            await self.page.wait_for_load_state("networkidle", timeout=timeout_ms)

            # 9. æå–æ’­å®¢ä¿¡æ¯
            podcast_data = await self._extract_podcast_data_from_page(limit, offset)

            logger.info(f"æ’­å®¢ä¸»é¡µè§£ææˆåŠŸ: {podcast_id}")
            return podcast_data

        except (InvalidURLException, Error403Exception, Error404Exception, Error504Exception):
            raise
        except Exception as e:
            logger.error(f"è§£ææ’­å®¢ä¸»é¡µæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
            raise Error504Exception(f"è§£æå¤±è´¥: {str(e)}")

    async def _extract_podcast_data_from_page(self, limit: int = 5, offset: int = 0) -> Dict:
        """ä»æ’­å®¢ä¸»é¡µæå–æ•°æ®

        Args:
            limit: æ¯é¡µæ•°é‡
            offset: åç§»é‡
        """
        try:
            # ä» __NEXT_DATA__ ä¸­æå–
            js_code = """
            () => {
                const nextDataScript = document.getElementById('__NEXT_DATA__');
                if (nextDataScript) {
                    try {
                        const data = JSON.parse(nextDataScript.textContent);
                        return { source: '__NEXT_DATA__', data };
                    } catch (e) {
                        console.error('è§£æ __NEXT_DATA__ å¤±è´¥:', e);
                    }
                }
                return { source: 'failed', data: null };
            }
            """
            result = await self.page.evaluate(js_code)

            if result.get('source') == '__NEXT_DATA__':
                return await self._parse_podcast_next_data(result['data'], limit, offset)
            else:
                raise ValueError("æ— æ³•ä»é¡µé¢æå–æ•°æ®")

        except Exception as e:
            logger.error(f"æå–æ’­å®¢æ•°æ®å¤±è´¥: {str(e)}", exc_info=True)
            raise

    async def _parse_podcast_next_data(self, data: dict, limit: int = 5, offset: int = 0) -> Dict:
        """è§£ææ’­å®¢ä¸»é¡µçš„ Next.js æ•°æ®

        Args:
            data: __NEXT_DATA__ å¯¹è±¡
            limit: æ¯é¡µæ•°é‡
            offset: åç§»é‡
        """
        try:
            # ä» __NEXT_DATA__ ä¸­æå–æ’­å®¢ä¿¡æ¯
            # è·¯å¾„: props.pageProps.podcast
            podcast_info = data.get('props', {}).get('pageProps', {}).get('podcast', {})

            if not podcast_info:
                # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
                podcast_info = data.get('props', {}).get('pageProps', {}).get('podcastData', {})

            if not podcast_info:
                raise ValueError("æ’­å®¢æ•°æ®ä¸ºç©º")

            # æå–æ’­å®¢åŸºæœ¬ä¿¡æ¯
            podcast_id = podcast_info.get('id') or podcast_info.get('pid', '')
            podcast_name = podcast_info.get('title') or podcast_info.get('name', '')
            podcast_description = podcast_info.get('description') or podcast_info.get('intro', '')

            # æå–ä¸»æ’­ä¿¡æ¯
            host_name = ""
            if 'podcasters' in podcast_info and podcast_info['podcasters']:
                host_name = podcast_info['podcasters'][0].get('name') or podcast_info['podcasters'][0].get('nickname', '')
            elif 'author' in podcast_info:
                host_name = podcast_info['author']

            # æå–å°é¢å›¾ï¼ˆlogoï¼‰
            logo_field = podcast_info.get('image') or podcast_info.get('cover') or podcast_info.get('logo')
            if isinstance(logo_field, dict):
                podcast_logo = (
                    logo_field.get('picUrl') or
                    logo_field.get('largePicUrl') or
                    logo_field.get('middlePicUrl') or
                    logo_field.get('smallPicUrl') or
                    ''
                )
            elif isinstance(logo_field, str):
                podcast_logo = logo_field
            else:
                podcast_logo = ''

            # æå–æœ€æ–° N é›†èŠ‚ç›®ï¼ˆæ”¯æŒåˆ†é¡µï¼‰
            episodes_data = podcast_info.get('episodes', [])
            latest_episodes = []

            # åº”ç”¨åˆ†é¡µ
            start_idx = offset
            end_idx = min(offset + limit, len(episodes_data))

            for ep in episodes_data[start_idx:end_idx]:
                episode_info = {
                    "episode_id": ep.get('id') or ep.get('eid') or ep.get('episode_id', ''),
                    "episode_title": ep.get('title') or ep.get('episode_title', ''),
                    "audio_url": ep.get('enclosure', {}).get('url') or ep.get('audio_url') or ep.get('url', ''),
                    "duration": ep.get('duration') or 0,
                    "cover_image": "",
                    "show_notes": ep.get('shownotes') or ep.get('show_notes') or ep.get('description', ''),
                    "created_at": ep.get('created_at') or ep.get('pubdate') or ep.get('publish_date', ''),
                }

                # æå–å•é›†å°é¢å›¾
                episode_image = ep.get('image') or ep.get('cover')
                if isinstance(episode_image, dict):
                    episode_info["cover_image"] = (
                        episode_image.get('picUrl') or
                        episode_image.get('largePicUrl') or
                        episode_image.get('middlePicUrl') or
                        podcast_logo  # å¦‚æœå•é›†æ²¡æœ‰å°é¢ï¼Œä½¿ç”¨æ’­å®¢logo
                    )
                elif isinstance(episode_image, str):
                    episode_info["cover_image"] = episode_image
                else:
                    episode_info["cover_image"] = podcast_logo

                latest_episodes.append(episode_info)

            logger.info(f"ä» __NEXT_DATA__ æˆåŠŸæå–æ’­å®¢æ•°æ®: {podcast_name}")
            logger.info(f"æå–åˆ°ç¬¬ {offset + 1}-{end_idx} é›†ï¼Œå…± {len(latest_episodes)} é›†")

            return {
                "podcast_id": podcast_id,
                "podcast_name": podcast_name,
                "host_name": host_name,
                "description": podcast_description,
                "logo": podcast_logo,
                "episodes": latest_episodes,
                "total_episodes": len(episodes_data)
            }

        except Exception as e:
            logger.error(f"è§£ææ’­å®¢ __NEXT_DATA__ å¤±è´¥: {str(e)}")
            raise

    async def _extract_data_from_page(self) -> Dict:
        """ä»é¡µé¢æå–æ•°æ®"""
        try:
            # æ–¹æ³•1: ä» Next.js çš„ __NEXT_DATA__ ä¸­æå–ï¼ˆå°å®‡å®™ä½¿ç”¨ Next.jsï¼‰
            js_code = """
            () => {
                // 1. å°è¯•ä» __NEXT_DATA__ è·å–
                const nextDataScript = document.getElementById('__NEXT_DATA__');
                if (nextDataScript) {
                    try {
                        const data = JSON.parse(nextDataScript.textContent);
                        return { source: '__NEXT_DATA__', data };
                    } catch (e) {
                        console.error('è§£æ __NEXT_DATA__ å¤±è´¥:', e);
                    }
                }

                // 2. ä» meta æ ‡ç­¾è·å–
                const metaTags = {};
                document.querySelectorAll('meta').forEach(tag => {
                    const property = tag.getAttribute('property') || tag.getAttribute('name');
                    const content = tag.getAttribute('content');
                    if (property && content) {
                        metaTags[property] = content;
                    }
                });

                return { source: 'metaTags', data: metaTags };
            }
            """
            result = await self.page.evaluate(js_code)
            logger.debug(f"æ•°æ®æå–æ¥æº: {result.get('source')}")

            # æ ¹æ®æ•°æ®æ¥æºè§£æ
            if result.get('source') == '__NEXT_DATA__':
                return await self._parse_next_data(result['data'])
            else:
                return await self._parse_meta_tags(result['data'])

        except Exception as e:
            logger.error(f"æå–é¡µé¢æ•°æ®å¤±è´¥: {str(e)}", exc_info=True)
            # ä½¿ç”¨æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
            return await self._extract_data_fallback()

    async def _parse_next_data(self, data: dict) -> Dict:
        """è§£æ Next.js æ•°æ®"""
        try:
            # ä» __NEXT_DATA__ ä¸­æå–èŠ‚ç›®ä¿¡æ¯
            # è·¯å¾„: props.pageProps.episode
            episode = data.get('props', {}).get('pageProps', {}).get('episode', {})

            if not episode:
                raise ValueError(" episode æ•°æ®ä¸ºç©º")

            # ğŸ” è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰å¯ç”¨å­—æ®µ
            logger.info(f"ğŸ“Š episode å¯¹è±¡çš„æ‰€æœ‰é”®: {list(episode.keys())}")
            logger.info(f"ğŸ“Š episode.get('enclosure'): {episode.get('enclosure')}")
            logger.info(f"ğŸ“Š episode.get('audio_url'): {episode.get('audio_url')}")
            logger.info(f"ğŸ“Š episode.get('url'): {episode.get('url')}")

            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯èƒ½åŒ…å«éŸ³é¢‘URLçš„å­—æ®µ
            for key in episode.keys():
                value = episode.get(key)
                if isinstance(value, str) and ('http' in value and ('mp3' in value or 'm4a' in value or 'mp4' in value)):
                    logger.info(f"âœ… å‘ç°å¯èƒ½åŒ…å«éŸ³é¢‘URLçš„å­—æ®µ: {key} = {value}")

            # æå–éŸ³é¢‘ URLï¼ˆä»å¤šä¸ªå¯èƒ½çš„å­—æ®µä¸­æŸ¥æ‰¾ï¼‰
            audio_url = (
                episode.get('enclosure', {}).get('url') or  # æ–°çš„æ•°æ®ç»“æ„
                episode.get('audio_url') or
                episode.get('url')
            )
            if not audio_url:
                raise ValueError("æ— æ³•æ‰¾åˆ°éŸ³é¢‘ URL")

            # ğŸ” æ£€æµ‹æ˜¯å¦æ˜¯æ’­æ”¾é¡µé¢è€ŒééŸ³é¢‘æ–‡ä»¶
            if self._is_playback_page(audio_url):
                logger.warning(f"âš ï¸ audio_url æŒ‡å‘æ’­æ”¾é¡µé¢è€ŒééŸ³é¢‘æ–‡ä»¶: {audio_url}")
                logger.info(f"ğŸ”„ å°è¯•ä»æ’­æ”¾é¡µé¢æå–çœŸå®éŸ³é¢‘URL...")

                # å°è¯•ä»å½“å‰é¡µé¢ä¸­ç›´æ¥æå–éŸ³é¢‘URL
                real_audio_url = await self._extract_audio_url_from_scripts()
                if real_audio_url and not self._is_playback_page(real_audio_url):
                    logger.info(f"âœ… æˆåŠŸæå–çœŸå®éŸ³é¢‘URL: {real_audio_url}")
                    audio_url = real_audio_url
                else:
                    logger.warning(f"âŒ æ— æ³•ä»é¡µé¢æå–éŸ³é¢‘URLï¼Œä½¿ç”¨åŸURLï¼ˆå¯èƒ½å¯¼è‡´è½¬å½•å¤±è´¥ï¼‰")
            else:
                logger.info(f"âœ… audio_url æ˜¯æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶URL: {audio_url}")

            # æå–å…¶ä»–ä¿¡æ¯
            title = episode.get('title') or episode.get('episode_title', '')
            podcast_name = episode.get('podcast', {}).get('title') or episode.get('podcast_name', '')

            # æå– podcast_id - å°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µ
            podcast_obj = episode.get('podcast', {})
            podcast_id = (
                podcast_obj.get('id') or
                podcast_obj.get('pid') or
                podcast_obj.get('podcast_id') or
                podcast_obj.get('base_id') or
                episode.get('podcast_id') or
                episode.get('pid') or
                ''
            )

            # è°ƒè¯•æ—¥å¿—
            logger.info(f"æå– podcast_id: {podcast_id}")
            if podcast_obj:
                logger.info(f"episode.get('podcast') keys: {list(podcast_obj.keys())}")
                logger.info(f"podcast_obj å†…å®¹: {podcast_obj}")

            # æå–å°é¢å›¾ï¼ˆimage å¯èƒ½æ˜¯å­—å…¸æˆ–å­—ç¬¦ä¸²ï¼‰
            image_field = episode.get('image')
            if isinstance(image_field, dict):
                # ä¼˜å…ˆä½¿ç”¨åŸå›¾ï¼Œå…¶æ¬¡å¤§å›¾ã€ä¸­å›¾ã€ç¼©ç•¥å›¾
                cover_image = (
                    image_field.get('picUrl') or
                    image_field.get('largePicUrl') or
                    image_field.get('middlePicUrl') or
                    image_field.get('smallPicUrl') or
                    image_field.get('thumbnailUrl') or
                    ''
                )
            elif isinstance(image_field, str):
                cover_image = image_field
            else:
                cover_image = (
                    episode.get('image_url') or
                    episode.get('cover_image') or
                    episode.get('coverUrl') or
                    episode.get('cover') or
                    episode.get('thumbnail') or
                    ''
                )

            # âœ… ä¼˜å…ˆä½¿ç”¨ shownotesï¼ˆHTMLæ ¼å¼ï¼‰ï¼Œå…¶æ¬¡ä½¿ç”¨ descriptionï¼ˆçº¯æ–‡æœ¬ï¼‰
            show_notes = episode.get('shownotes') or episode.get('show_notes') or episode.get('description', '')

            duration = episode.get('duration') or 0

            logger.info(f"ä» __NEXT_DATA__ æˆåŠŸæå–æ•°æ®: {title}")
            logger.info(f"shownotes é•¿åº¦: {len(show_notes)}, åŒ…å«HTML: {'<' in show_notes}, å‰50å­—ç¬¦: {show_notes[:50]}")

            episode_id = self._extract_episode_id(self.page.url)
            return {
                "episode_id": episode_id,
                "podcast_id": podcast_id,  # æ·»åŠ  podcast_id
                "audio_url": audio_url,
                "duration": duration,
                "cover_image": cover_image,
                "show_notes": show_notes,
                "episode_title": title,
                "podcast_name": podcast_name
            }

        except Exception as e:
            logger.error(f"è§£æ __NEXT_DATA__ å¤±è´¥: {str(e)}")
            raise

    async def _parse_meta_tags(self, meta: dict) -> Dict:
        """è§£æ meta æ ‡ç­¾æ•°æ®"""
        try:
            # ä» meta æ ‡ç­¾æå–
            audio_url = meta.get('og:audio') or meta.get('audio')
            title = meta.get('og:title') or ''
            image = meta.get('og:image') or ''
            description = meta.get('og:description') or meta.get('description') or ''

            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰éŸ³é¢‘URLï¼Œå°è¯•ä» script æ ‡ç­¾ä¸­æŸ¥æ‰¾
            if not audio_url:
                audio_url = await self._extract_audio_url_from_scripts()

            if not audio_url:
                raise ValueError("æ— æ³•æå–éŸ³é¢‘ URL")

            episode_id = self._extract_episode_id(self.page.url)

            return {
                "episode_id": episode_id,
                "audio_url": audio_url,
                "duration": 0,  # meta æ ‡ç­¾å¯èƒ½ä¸æä¾›æ—¶é•¿
                "cover_image": image,
                "show_notes": description,
                "episode_title": title,
                "podcast_name": ""  # meta æ ‡ç­¾å¯èƒ½ä¸æä¾›æ’­å®¢åç§°
            }
        except Exception as e:
            logger.error(f"è§£æ meta æ ‡ç­¾å¤±è´¥: {str(e)}")
            raise

    async def _extract_audio_url_from_scripts(self) -> Optional[str]:
        """ä» script æ ‡ç­¾ä¸­æå–éŸ³é¢‘ URL"""
        try:
            # è·å–æ‰€æœ‰ script æ ‡ç­¾çš„å†…å®¹
            scripts = await self.page.query_selector_all('script')
            for script in scripts:
                text = await script.inner_text()
                # æŸ¥æ‰¾åŒ…å« .mp3 çš„ URL
                match = re.search(r'https?://[^\s"\'<>]+\.mp3[^\s"\'<>]*', text)
                if match:
                    return match.group(0)
            return None
        except Exception as e:
            logger.debug(f"ä» scripts æå–éŸ³é¢‘ URL å¤±è´¥: {str(e)}")
            return None

    async def _extract_data_fallback(self) -> Dict:
        """å¤‡ç”¨æ•°æ®æå–æ–¹æ³•"""
        logger.warning("ä½¿ç”¨å¤‡ç”¨æ•°æ®æå–æ–¹æ³•")

        # æå–é¡µé¢æ ‡é¢˜
        title = await self.page.title()
        # æå–æè¿°
        description = await self.page.evaluate("""
            () => {
                const desc = document.querySelector('meta[name="description"]');
                return desc ? desc.getAttribute('content') : '';
            }
        """)

        # æå–å°é¢å›¾
        image = await self.page.evaluate("""
            () => {
                const img = document.querySelector('meta[property="og:image"]');
                return img ? img.getAttribute('content') : '';
            }
        """)

        # æå–éŸ³é¢‘ URLï¼ˆæœ€å…³é”®ï¼‰
        audio_url = await self._extract_audio_url_from_scripts()

        if not audio_url:
            # å°è¯•ä» audio æ ‡ç­¾è·å–
            audio_url = await self.page.evaluate("""
                () => {
                    const audio = document.querySelector('audio');
                    return audio ? audio.src : '';
                }
            """)

        if not audio_url:
            raise ValueError("æ— æ³•æå–éŸ³é¢‘ URL")

        episode_id = self._extract_episode_id(self.page.url)

        return {
            "episode_id": episode_id,
            "audio_url": audio_url,
            "duration": 0,  # é»˜è®¤å€¼ï¼Œåç»­å¯èƒ½éœ€è¦ä»éŸ³é¢‘æ–‡ä»¶æœ¬èº«è·å–
            "cover_image": image,
            "show_notes": description,
            "episode_title": title,
            "podcast_name": ""  # å¤‡ç”¨æ–¹æ³•å¯èƒ½æ— æ³•è·å–
        }


# å…¨å±€çˆ¬è™«å®ä¾‹
crawler = XiaoyuzhouCrawler()
